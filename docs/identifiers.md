## Identifiers used within Systems

Basically what we're talking about is various "IDs" that are to refer to things within the system.

It's common to find in your software system a veritable zoo of IDs, many of which seem overlapping,
or even redundant. This zoo will grow organically as developers identify a new use case and determine
that there are no existing ID's in the system that will suffice. This determination could be accurate,
or it could be inaccurate, due to a lack of awareness of all the IDs available, a lack of understanding
of the available IDs, or a non-meaningful distinction that is being made between the new use case
and existing use cases.

Despite the variety of ways new IDs can be introduced needlessly, it would be a mistake to assume
that multiple IDs are never necessary. In the next section of this document, we will discuss some
of the different species of IDs that may be appropriately distinguished.

## Species of Identifiers

### Request ID / Idempotency Key

The purpose of a request ID is to prevent duplicate processing of duplicate requests (which is why it
is sometimes referred to as an idempotency key). Duplicate requests can happen for any number of reasons,
generally related to an attempt to retry the request when the response was not received, or not received
quickly enough.

The request ID is generated by the client and sent in the request. The server is responsible for keeping
track of the request IDs it has received, and using these to deduplicate requests, as described below.

#### Limits on Request IDs

As with any field in a request, the server is free to define reasonable limitations on the allowed values
for a request ID. The server should absolutely tree the request ID as an opaque value, so the limitations
for it should only be on the maximum size allowed. Requests that include a too-long request ID can be
rejected as invalid requests (400 status code). In this way, the server can curtail the amount of storage
it requires for tracking request IDs.

#### Scoping by Endpoint

It is advisable that request IDs be scoped to the specific request path and HTTP method of the request.
This scoping reduces the pool of possible collisions, and could reduce the burden for clients who have
different services making use of different end points.

This also opens the possibility of including the request ID in the request PATH itself, in the query string
or otherwise.

#### Scoping by Timeframe

To limit the number of IDs the server has to store, it can limit the deduplication to a reasonable time
frame, such as a few hours or days. With such a scope defined, the server makes no guarantees that duplicate
requests made outside this timeframe will be deduplicated, so it is up to the client to make sure retries
or other sources of request duplication do not exceed this timeframe.

At the same time, the server does not need to guarantee _not_ to deduplicate requests beyond this time frame.
The time frame puts an upper limit on how long the server _must_ store request IDs. To be clear about it,
clients should _not_ assume that there is any period of time after which they can safely reuse a request ID
for a _different_ request.

#### Scoping by Client

In cases where there is a meaningful way to identify the client, it is strongly advisable for the server
to scope the request ID to that client. This prevents clients from accidentally, or intentionally, causing
another client's request to be deduplicated.

In a closed system, for instance, (in which all services are owned by the same organization) there may be
standards to place the name of the service in a request header.

In other cases, clients may need to be preregistered and identify themselves using an API key or some other form
of identification. In such cases, you need to determine the appropriate level at which to scope request IDs. For
instance, if a client system has multiple API keys that it can use, should request IDs be scoped to the API key,
or the client that owns them. This is largely a question of how request IDs are expected to be generated and how
API keys are expected to be used: if there are multiple instances of a service, each with their own API key and
each responsible for retrying its own requests, then scoping the request ID to the API key is probably appropriate.
However, if each such instance has it's own API key but is consuming work items from a shared queue such that
request retries might originate from different instances and therefore different API keys, then scoping request IDs
to the individual API keys would be inappropriate and allow duplicate requests to go through.

Note that the following should _not_ be considered an appropriate way to identify a client: IP address,
`user-agent` header value. These values do not have strong enough guarantees of being unique across distinct clients,
nor of bing consistent for the same client over duplicated requests.

When no such client is readily recognizable in a request, request IDs need to be deduplicated across all clients.
In this case, a strong guarantee of uniqueness will be required to prevent incorrect deduplication. In this case,
servers SHOULD support UUID's as request IDs, and clients SHOULD use UUIDv7 to generate their request IDs. Clients
can alternatively use UUIDv4, but using UUIDv7 is a favor to the server as they may be more friendly to databases.

The risk of non-random request IDs, when not scoped to a client, is that a malicious actor could pre-emptively make
a request to the server with a request ID that they expect another client to use, thereby causing the other client's
request to be ignored as a duplicate, acting as a Denial of Service attack. Strictly, this is possible with randomly
generated request IDs as well, but UUIDv4 or v7 offer a very high degree of randomness, making it very unlikely an
attacker could guess what ID will be used by another client. To further limit the risk, servers should implement an
appropriately tight timeframe for deduplication, as described above. This will limit the number of guesses a malicious
actor can effectively make. Further more, a response header indicating whether or not the request was identified
as a duplicate can help alert a client when they may have been victims of such an attack.

#### Deduplicating Requests

The server should still respond to requests identified as duplicate. Failing to do so will most likely lead to more
duplicate requests.

It is generally advisable to respond with the same response body and status code that were generated for the initial
request. In this way, if both responses eventually are received by the upstream, there will be no ambiguity.
Additionally, if the response to the initial request is truly lost and only the response to the duplicate is received
by the client, this response will need to contain all the information the client expects to receive from its request.

While all the semantic parts of the responses should be the same for duplicate requests, a response header indicating
whether or not the request was identified as a duplicate SHOULD be sent by the server. This can help the client identify
if requests have been _unexpectedly_ deduplicated, either because a flaw in their system is reusing request IDs or
making the same request multiple times; or because another client, possibly malicious, is issuing requests with the same
request IDs.

Additional information that the server MAY send in response headers (if the information is readily available to it)
includes the time at which the original request was received, and the total number of requests the server has
received for this duplicated ID.

Lastly, the client MAY send a request header indicating how many times it believes it has issued this same request
to the server. Alternatively to a counter, the client MAY use another unique ID for this value. In either case,
we refer to the value as the _attempt ID_, and it is meaningful only in the context of the specific request.

If the _attempt ID_ is present in the request, the server SHOULD send back the same value in a response header,
and MAY send back the _attempt ID_ of the _original_ request that it processed.

The server _MUST NOT_ consider the attempt ID when deciding if the request is a duplicate; the whole point of the
value is to identify whether or not each attempt of the same request was deduplicated.

#### Client Responsibilities for Request IDs.

It is incumbent on the client to ensure that they are not reusing request IDs for distinct requests, within the
server-defined scope of deduplication (as described above). In particular, the server is NOT responsible for
determinging whether or not two requests are semantically or in any other way equivalent before deduplicating them.
In other words, if the client uses the same request ID for requests that are semantically different, the server
need not care that the requests are meaningfully different and MAY treat them as duplicates.

As noted above, if the server specifies a maximum time frame for deduplication, this should be treated as the
minimum timeframe over which deduplication may apply, and clients MUST NOT assume that request IDs can be reused
beyond this timeframe.

In some cases, a request ID derived from the semantic values of the request _may_ be appropriate, however there are
two important notes about doing some. First, it means that the service will _not_ be able to make a distinct but
semantically identical request again, as it will have the same request ID and may be deduplicated. Second, it means
that request IDs may be predictable and, depending on the openness of the system and the scoping of reuqest IDs,
could allow a malicious actor to perform a denial of service attack by preemptively using a request ID your client
will want to use in the future. For these reasons, a client generally SHOULD generate request IDs independent of
the request details.

Another option is for a client to track an atomic, monotonically increasing value, to use as the request ID (or
from which the request ID may be derived). Depending on the complexity of the system, this may be sufficient for
the client's purposes, however it still leaves the client open to the Denial of Service attack described above.

For these reasons, the client SHOULD use large, strongly-random values for their request IDs, within the size-limits
defined by the server. When the size-limits permit, a client SHOULD generate UUIDv7 request IDs. Alternatively, a
client MAY generate UUIDv4 request IDs. Both of these provide strong degrees of randomness from a very large pool
of possible values, making accidental or malicious collisions very unlikely.

### Reference IDs

A Reference ID is a value that a client and server can use to refer to the same thing. For instance, when an API
is used to create an Entity on the server, a Reference ID is what the server and the client can then use to refer
to that entity. Or if an API is used to create an asynchronous job, a Reference ID to that job might be used by
the client in subsequent requests to ask for the status or results of that job, and it might be sent by the server
back to the client in a callback related to that job.

When reasonable, a Reference ID SHOULD originate with the client, and be sent as part of the request. This way, even
if the response is dropped, the client will still know the Reference ID to ask the server about the request.

When a single request spawns multiple entities of interest to the client, it may be necessary to send Reference IDs
for these entities back to the client in the response. There are cases where this can be avoided, as described below,
but when it cannot be avoided, the server SHOULD still accept a Reference ID from the client and let it refer to
the entire collection of relevant entities, in which case we can also call the client's original Reference ID
as the _Batch ID_. The server SHOULD still send the individual Reference IDs back in the
response, but SHOULD also support an API for fetching those Reference IDs by the _Batch ID_. In this way, the client
can again get all the necessary information even if the response itself is lost.

Even when a single request spawns multiple entities, if the client's request dictates how many such entities will
be created, then the server SHOULD support having the client specifying the individual Reference IDs in the request.
In this case, the server MAY also accept a top-level Refernce ID in the request to serve as the Batch ID, as described
above.

Whenever a Reference ID is provided by a client, the server MAY still dictate the schema for the ID. While the server
MUST treat client provided Reference IDs as opaque values, it MAY still specify the allowed type or types for the IDs,
and SHOULD specify maximum sizes for the IDs, to curtail the storage space required on the server. The server SHOULD
validate requests against this schema and reject requests that violate it as invalid (with a 400 response code).

For the convenience of the clients, the server SHOULD support string valued Reference IDs with a length sufficient
for UUIDs. To avoid ambiguity, the server SHOULD NOT support multiple types for Reference IDs that might be used in
the same way (e.g., allowing both the string value `"123"` and the numeric value `123` for the same ID can be confusing
as to whether or not those values are equivalent, and will likely lead to bugs in either the client or the server).

When the server's schema supports it, clients SHOULD use UUIDv7 values for Reference IDs when possible, as they are
friendly to databases.

For client-supplied Reference IDs, the server SHOULD scope the IDs as narrowly as is possible and appropriate. When
a distinct client is identifiable from a request, the Reference ID should be scoped to that client, so that one client's
`"123"` does not refer to the same thing as any other client's `"123"`. Do not confuse this with the scoping of Request ID's,
however: it is often inappropriate to scope Reference IDs by timeframe, or by the endpoint (specifically
when there are multiple endpoints that can be used to spawn or refer to the same the entities).

Clients generally SHOULD NOT treat a Reference ID and a Request ID as equivalent. This may seem appealing, for instance,
when making a single request to create an entity. Broadly speaking, these two identifiers have different uses and
mean different things, so treating them as equivalent would be an instance of _type punning_, and is likely to lead to
problems.

As one example of how this might be problematic, suppose a client wants to create entities in the server that have
a one-to-one correspondance with entities of its own, and so it derives a Reference ID from it's internal entity.
If it uses this same ID as both the Reference ID and the Request ID, successfully creates the entity on the server,
but the entity is then removed from the server, the client will not be able to recreate the same entity on the server,
because it's request will be deduplicated.

Give to the deduplication system that which is for deduplication, and give to the entity system that which is for entities.

### Internal Entity IDs

Similar to a Reference ID, but an Internal Entity ID, or simply an Entity ID, is used within a system to refer to a particular
entity.

When an entity is created by, or because of, an external request, you may be tempted to use the client provided Reference ID
for that entity's Entity ID. This is generally not advisable, as it couples the creation of these entities to an external
request. If your system then finds a need to spotaneously create these entities of its own accord, it will have no Reference
ID to use. If the server were to generate it's own Reference ID for these purposes, you would need to ensure it doesn't collide
with those provided by clients. Alternatively, if the server is effectively scoping Reference IDs to the client, then you can
treat the server itself as a distinct client, and it can safely generate it's own scoped Reference ID for this purpose.

When you are, as advised, treating the Reference ID and the Entity ID as distinct, it will generally be necessary to store the
Reference ID (appropriately scoped) in association with the entity, in cases where external references to the entity will be
necessary.

### Primary Keys

A Primary Key in a datastore should be treated as an implementation detail of that specific datastore, and it should be used
as minimally as possible. Generate Entity IDs idependently of their primary keys, and use the Entity ID exclusively to represent
that entity (within your service; external to your service you should be using a Reference ID). If you do this, changing the primary
key of an entity (such as if you are moving entities to a different datastore, or changing the type of the pimrary key), or reusing
the primary key of a long-deleted entity, should not cause any problems as the primary keys are never used outside of the datastore
itself. 

### Correlation IDs

In some systems, we introduce correlation IDs for the purposes of tracing the progress of a request or other work item through the
system. As such, the correlation ID is associated with a unit of work, _not_ with any entities. Even when a unit of work is stored
or otherwise represented as an entity, the unit of work is distinct from the entity that represents it, and the correlation ID SHOULD
therefore be distinct from any IDs associated with the entity.

In general, this also means that a correlation ID should _not_ be stored in an entity, though there may be cases where it is
convenient to do so in order to maintain continuity of that correlation ID through asynchronous work, when it is not able to
be passed along with the work.

Where a correlation ID is present, it should be included in all logs so that the complete "story" of that one work item can be
traced through the logs. While it may be tempting to use a Request ID, a Reference ID, or an Entity ID, none of these are good
choices for a correlation ID, as described in the following paragraphs.

A Request ID is duplicated across duplicate requests, and since deduplication involves processing, the processing of each
request, duplicated or not, should have it's own Correlation ID.

A Reference ID or an Entity ID can be included in logs to tell the story of that entity, but that is a different story from the work
items that happen to interact with that entity.

A unit of work frequently spans across multiple services, and as such, the Correlation ID should go with it. Within a system, the
Correlation ID SHOULD be passed along in a request, a broadcast message, a queue message, etc.

#### Splitting / Extending Correlation IDs

When a unit of work spawns other distinct units of work, it is generally appropriate to _extend_ the correlation ID by appending
a new value to it. This should be done sparingly, to prevent the correlation ID from getting too large, but it is warranted when
independent and otherwise-indistinguishable work items are spawned. By extending instead of replacing the correlation ID, you can
still find the entirety of the parent work item's story, including that of it's descendants, by searching for it's correlation ID
as a prefix. On the other hand, you still want to be able to distinguish the story of each descendant from those of it's siblings,
so they need to have distinct correlation IDs.

When extending a correlation ID, brevity is important. When child work items are spawned through any form of iteration, extending
the _parent's_ correlation ID with an incrementing value is appropriate: `abcd-efgh.1`, `abcd-efgh.2`, etc.

When the iteration is over a collection of items that each have a unique identifier, it may be tempting to use the item's identifier
as the extension. This MAY be done, and can be useful, but it will tend to grow your correlation IDs very quickly. The alternative
would be to use the counter extension as described above, and include the item's identifier as a separate piece of information in the
log.

In other cases, we may have to extend a correlation ID without any knowledge of other extensions to it. For instance, a queue message
SHOULD have it's own correlation ID, but in cases where it may be reprocessed due to failure, you should have a unique extension for
each time it is processed. In such cases, you likely won't know how many times you've processed it. To ensure a unique extension for
each processing, you will likely want to extend it with a random value, and one that is large enough to suitably limit the chance of
collission with other processings. While a UUIDv7 or v4 is a common and usually commendable choice for generating random IDs, you would
do well to limit the size of the random extension based on how many parallel extensions you will actually need. For instance, if your
queue has a maximum of 10 times it will deliver the same message, then you will only need at most 10 extensions for a given correlation ID.
The 74 bits of randomness within the millisecond scope of a UUIDv7 is probably superfluous: a 24 bit random value would give you
less than 1 in a million chance of a collision, and produce a much smaller extended correlation ID (4 characters in base-64). In a situation
like this, the queue will likely wait some minimum amount of time before redeliverying the message, so a timestamp can be very effective
in an extension. For instance, if your queue waits 1 minute before delivery and has a maximum of 10 deliveries per message, you could use
the lower 8 bits of a 30-second resolution timestamp (covering just over 2 hours and still more precise than needed), concatenated to a
10 bit random value, encoded in base-64 to 3 characters, and have virtually no possibility for collision.

Note that not every iteration requires extending/splitting a work item. For instance, in a synchronous iteration, it may be perfectly
sufficient to leave the correlation ID alone, and simply emit something in the log indicating which iteration item you're working on.
It depends really on whether you want to consider each iteration to have it's own unique story (indicating they should have their own
extended correlation ID), or for the iterations to be nothing more than details of the same story.

#### Replacing Correlation IDs

Through repeated extension, you may find that your correlation IDs are getting unreasonably long. At this point, you can choose to
_replace_ the correlation ID with a fresh, random value. Like extension, replacement should be done sparingly as it makes it difficult
to follow the story. When you _do_ replace a correlation ID, you should immediately emit a logs to tie the two chapters together.
The recommended practice for this is:

1. Generate the new correlation ID.
2. Emit a log message "Replacing correlation id" with the old correlation ID included in the normal way, and the new correlation ID
   indicated (e.g., `"Replacing correlation id [corr_id=${OLD_CORR_ID}] [new_corr_id=${NEW_CORR_ID}]"`).
3. Put the new correlation ID in place.
4. Emit a log message "Replaced correlatin id" with the new correlation ID incldued in the normal way, and the old correlation ID indicated
   (e.g., `"Replaced correlation id [corr_id=${NEW_CORR_ID}] [old_corr_id=${OLD_CORR_ID}]"`

In this way, whether you are starting with the old or the new correlation ID, you'll be able to find the log indicating the switch, and
use it to find the other half of the story.

It is important, of course, that you emit this log at a level where it will not be filtered out by logging thresholds.

#### Combining Correlation IDs

The _replacement_ process described above is also appropriate when you have a need to combine multiple correlation IDs as well, such as
if multiple distinct work items are being batched together into a single work item. In such a case, you can perform the replacement
process described above for each of the incoming correlation IDs, indicating that they are each replaced by the _same_ new correlation ID.
This is preferred to emitting a single pair of logs indicating all the replacments together, because if you are following the story of any
of the individual items, you will still find the log indicating replacement without having to search for something different than it's
correlation ID in the appropriate scalar location.

#### Restoring Correlation IDs

There may also be cases where a correlation ID is passed along but is not immediately available to the processor receiving it. For instance,
if the correlation ID is passed in a request, extracting that correlation ID might not be possible until the request is parsed, which may also
include deduplicating and validating the request before the processor can get the correlation ID. All of this time processing should have a
correlation ID of it's own for any logs emitted. This correlation ID will likely be a fresh, randomly generated on. Once the correlation ID
is available and extracted, the processor can go through the correlation ID _replacment_ process described above to adopt the correlation ID
and continue the story.
